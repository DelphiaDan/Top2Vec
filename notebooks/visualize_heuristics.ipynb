{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heuristics Visualization\n",
    "This notebook is a demonstration of how the elbow finding heuristics will work on different datasets.\n",
    "It is intended for experimentation and to determine if any adjustments should be made to handle cases such as an S-curve along the expected linear descent line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from top2vec.cutoff_heuristics import (\n",
    "    find_cutoff,\n",
    "    get_distances_from_line,\n",
    "    _get_shifted_second_derivative,\n",
    "    ELBOW_HEURISTIC_STR,\n",
    "    DERIVATIVE_HEURISTIC_STR,\n",
    "    AVERAGE_HEURISTIC_STR,\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_heuristic(\n",
    "    values,\n",
    "    figure_num=\"1\",\n",
    "    figsize=(8, 3),\n",
    "    first_elbow=True,\n",
    "    below_line_exclusive=True,\n",
    "    max_first_delta=0.33\n",
    "):\n",
    "    sorted_values = -np.sort(-np.array(values))\n",
    "    x = np.arange(sorted_values.size)\n",
    "\n",
    "    m = (sorted_values[-1] - sorted_values[0]) / (sorted_values.size - 1)\n",
    "    line = x * m + sorted_values[0]\n",
    "\n",
    "    # Uniform is an absolute value and therefore useless for detecting an inflection\n",
    "    # y_distances = get_distances_from_line(\n",
    "    #    sorted_values, m, sorted_values[0], metric=\"raw-y\", first_elbow=False\n",
    "    # ).distances\n",
    "\n",
    "    elbow = find_cutoff(\n",
    "        sorted_values,\n",
    "        cutoff_heuristic=ELBOW_HEURISTIC_STR,\n",
    "        first_elbow=first_elbow,\n",
    "        below_line_exclusive=below_line_exclusive,\n",
    "        max_first_delta=max_first_delta\n",
    "    )\n",
    "    distances_tuple = get_distances_from_line(\n",
    "        sorted_values, m, sorted_values[0], first_elbow=first_elbow\n",
    "    )\n",
    "    y_distances = distances_tuple.y_deltas\n",
    "\n",
    "    slid_second_derivative = _get_shifted_second_derivative(\n",
    "        sorted_values, distances_tuple.is_truncated, distances_tuple.truncation_index\n",
    "    )\n",
    "    scores = (\n",
    "        distances_tuple.distances[: distances_tuple.truncation_index + 1]\n",
    "        * slid_second_derivative\n",
    "    )\n",
    "    alt_elbow = find_cutoff(\n",
    "        sorted_values,\n",
    "        cutoff_heuristic=DERIVATIVE_HEURISTIC_STR,\n",
    "        first_elbow=first_elbow,\n",
    "        below_line_exclusive=below_line_exclusive,\n",
    "        max_first_delta=max_first_delta\n",
    "    )\n",
    "    average_elbow = find_cutoff(\n",
    "        sorted_values,\n",
    "        cutoff_heuristic=AVERAGE_HEURISTIC_STR,\n",
    "        first_elbow=first_elbow,\n",
    "        below_line_exclusive=below_line_exclusive,\n",
    "        max_first_delta=max_first_delta\n",
    "    )\n",
    "    ELBOW_COLOR = \"blue\"\n",
    "    DERIVATIVE_COLOR = \"orange\"\n",
    "    AVERGE_COLOR = \"green\"\n",
    "    # PLOTS ON PLOTS\n",
    "    fig = plt.figure(num=figure_num, clear=True, figsize=figsize)\n",
    "\n",
    "    gs = fig.add_gridspec(nrows=3, ncols=3)\n",
    "    ax = fig.add_subplot(gs[:2, 0])\n",
    "    ax.plot(line)\n",
    "    ax.scatter([elbow], [sorted_values[elbow]], color=ELBOW_COLOR)\n",
    "    ax.scatter([alt_elbow], [sorted_values[alt_elbow]], color=DERIVATIVE_COLOR)\n",
    "    ax.scatter([average_elbow], [sorted_values[average_elbow]], color=AVERGE_COLOR)\n",
    "    ax.plot(sorted_values)\n",
    "\n",
    "    ax_y = fig.add_subplot(gs[2, 0])\n",
    "    ax_y.axhline(0, color=\"black\")\n",
    "    ax_y.plot(y_distances)\n",
    "    ax_y.scatter([elbow], [y_distances[elbow]], color=ELBOW_COLOR)\n",
    "    ax_y.scatter([alt_elbow], [y_distances[alt_elbow]], color=DERIVATIVE_COLOR)\n",
    "    ax_y.scatter([average_elbow], [y_distances[average_elbow]], color=AVERGE_COLOR)\n",
    "\n",
    "    ax_d = fig.add_subplot(gs[0, 1])\n",
    "    ax_d.plot(distances_tuple.distances[: distances_tuple.truncation_index + 1])\n",
    "    ax_d.axhline(0, color=\"black\")\n",
    "    ax_d.scatter([elbow], [distances_tuple.distances[elbow]], color=ELBOW_COLOR)\n",
    "    ax_d.xaxis.set_ticklabels([])\n",
    "    ax_val_second_d = fig.add_subplot(gs[1, 1])\n",
    "    ax_val_second_d.plot(slid_second_derivative)\n",
    "    ax_val_second_d.scatter(\n",
    "        [alt_elbow], [slid_second_derivative[alt_elbow]], color=DERIVATIVE_COLOR\n",
    "    )\n",
    "    ax_val_second_d.axhline(0, color=\"black\")\n",
    "    ax_val_scores = fig.add_subplot(gs[2, 1])\n",
    "    ax_val_scores.plot(scores)\n",
    "    ax_val_scores.scatter([alt_elbow], [scores[alt_elbow]], color=DERIVATIVE_COLOR)\n",
    "    ax_val_scores.axhline(0, color=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manufactured Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.array([[2, 1]])\n",
    "base = np.array(\n",
    "    [\n",
    "        [0, 1],\n",
    "        [2, 1],\n",
    "        [1, 0.5],\n",
    "        [1, 0],\n",
    "        [-1, 2],\n",
    "    ]\n",
    ")\n",
    "opposite = np.array(\n",
    "    [\n",
    "        [-2, -0.8],\n",
    "        [-2, -0.9],\n",
    "        [-2, -0.95],\n",
    "        [-2, -1],\n",
    "        [-2, -1.05],\n",
    "        [-2, -1.1],\n",
    "        [-2, -1.2],\n",
    "        [-2, -1.5],\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_embedding = np.vstack(\n",
    "    [\n",
    "        np.array(\n",
    "            [\n",
    "                [4, 2],\n",
    "                [8, 4],\n",
    "                [1, -1],\n",
    "            ]\n",
    "        ),\n",
    "        base,\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_embedding_multiple_elbows = np.vstack([test_embedding, opposite])\n",
    "\n",
    "# A different divergent case where the S-curve goes the other way\n",
    "test_embedding_multiple_elbows_2 = np.vstack(\n",
    "    [base, opposite, np.full((10, 2), [1, -1])]\n",
    ")\n",
    "\n",
    "sims = 1 - sklearn.metrics.pairwise_distances(vector, test_embedding, metric=\"cosine\")\n",
    "sims_multiple_elbows = 1 - sklearn.metrics.pairwise_distances(\n",
    "    vector, test_embedding_multiple_elbows, metric=\"cosine\"\n",
    ")\n",
    "sims_multiple_elbows_2 = 1 - sklearn.metrics.pairwise_distances(\n",
    "    vector, test_embedding_multiple_elbows_2, metric=\"cosine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show heuristic performance on simple embedding - one elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The current elbow-finding heuristic also showing changes in distance from the line\n",
    "plot_heuristic(\n",
    "    sims[0],\n",
    "    figure_num=\"Basic - Distance\",\n",
    "    figsize=(18, 8),\n",
    "    first_elbow=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing heuristic performance with multiple elbows in graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The current elbow-finding heuristic also showing changes in distance from the line\n",
    "plot_heuristic(\n",
    "    np.hstack((sims_multiple_elbows[0], [-1.5])),\n",
    "    figure_num=\"2 Elbows - Exclusive\",\n",
    "    figsize=(18, 8),\n",
    "    first_elbow=False,\n",
    "    below_line_exclusive=True,\n",
    ")\n",
    "plot_heuristic(\n",
    "    np.hstack((sims_multiple_elbows[0], [-1.5])),\n",
    "    figure_num=\"2 Elbows - Inclusive\",\n",
    "    figsize=(18, 8),\n",
    "    first_elbow=False,\n",
    "    below_line_exclusive=False,\n",
    ")\n",
    "plot_heuristic(\n",
    "    np.hstack((sims_multiple_elbows[0], [-1.5])),\n",
    "    figure_num=\"2 Elbows - First Elbow\",\n",
    "    figsize=(18, 8),\n",
    "    first_elbow=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yet another form of a graph with multiple elbows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The current elbow-finding heuristic also showing changes in distance from the line\n",
    "plot_heuristic(\n",
    "    sims_multiple_elbows_2[0],\n",
    "    figure_num=\"3 Elbows\",\n",
    "    figsize=(18, 8),\n",
    "    first_elbow=False,\n",
    ")\n",
    "plot_heuristic(\n",
    "    sims_multiple_elbows_2[0],\n",
    "    figure_num=\"3 Elbows - First Elbow\",\n",
    "    figsize=(18, 8),\n",
    "    first_elbow=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example of running only on the stuff which was already determined to be similar\n",
    "# but in this case it appears that we want our elbow to be exclusive, not inclusive\n",
    "\n",
    "sample_data = np.array(\n",
    "    [\n",
    "        0.87387407,\n",
    "        0.8490747,\n",
    "        0.83483994,\n",
    "        0.80989516,\n",
    "        0.45845926,\n",
    "        0.45052826,\n",
    "        0.44408453,\n",
    "        0.4278804,\n",
    "        0.4249642,\n",
    "        0.41800153,\n",
    "        0.415339,\n",
    "        0.40166456,\n",
    "        0.4011852,\n",
    "        0.3939832,\n",
    "        0.38374978,\n",
    "        0.3823452,\n",
    "        0.37897837,\n",
    "        0.37643087,\n",
    "        0.37551993,\n",
    "        0.37453377,\n",
    "        0.37433827,\n",
    "        0.3703115,\n",
    "        0.36441594,\n",
    "        0.3591773,\n",
    "        0.35516483,\n",
    "        0.35450447,\n",
    "        0.35071152,\n",
    "        0.34965813,\n",
    "        0.3412869,\n",
    "        0.3399775,\n",
    "        0.33868152,\n",
    "        0.33400196,\n",
    "        0.315881,\n",
    "    ]\n",
    ")\n",
    "\n",
    "plot_heuristic(\n",
    "    sample_data,\n",
    "    figure_num=\"Online data\",\n",
    "    figsize=(18, 8),\n",
    "    first_elbow=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 100000 -r 10 elbows = find_cutoff(sims_multiple_elbows_2[0], cutoff_heuristic=ELBOW_HEURISTIC_STR, first_elbow=False)\n",
    "%timeit -n 100000 -r 10 elbows = find_cutoff(sims_multiple_elbows_2[0], cutoff_heuristic=ELBOW_HEURISTIC_STR, first_elbow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if it is the same shape but much larger?\n",
    "print(sims_multiple_elbows_2.shape)\n",
    "big_sims = np.tile(sims_multiple_elbows_2, 1000000)\n",
    "print(big_sims.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 10 -r 5  elbows = find_cutoff(big_sims[0], cutoff_heuristic=ELBOW_HEURISTIC_STR, first_elbow=False)\n",
    "%timeit -n 10 -r 5  elbows = find_cutoff(big_sims[0], cutoff_heuristic=ELBOW_HEURISTIC_STR, first_elbow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics\n",
    "This has 3 elbows so we expect to have a substantial performance boost from using first_elbow\n",
    "\n",
    "#### Size 23\n",
    "17.4 µs ± 505 ns per loop (mean ± std. dev. of 10 runs, 100,000 loops each)  \n",
    "18.9 µs ± 428 ns per loop (mean ± std. dev. of 10 runs, 100,000 loops each)  \n",
    "\n",
    "\n",
    "#### Size 230,000\n",
    "5.43 ms ± 12.6 µs per loop (mean ± std. dev. of 5 runs, 100 loops each)  \n",
    "5.47 ms ± 31.2 µs per loop (mean ± std. dev. of 5 runs, 100 loops each)  \n",
    "\n",
    "#### Size 2,300,000\n",
    "57.7 ms ± 845 µs per loop (mean ± std. dev. of 5 runs, 10 loops each)  \n",
    "58.1 ms ± 157 µs per loop (mean ± std. dev. of 5 runs, 10 loops each)  \n",
    "\n",
    "#### Size 23,000,000\n",
    "632 ms ± 1.5 ms per loop (mean ± std. dev. of 5 runs, 10 loops each)  \n",
    "649 ms ± 573 µs per loop (mean ± std. dev. of 5 runs, 10 loops each)  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b5bb79fefaf98f77375acff079b7a24467080b30246462856d9cd8768ef704d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
