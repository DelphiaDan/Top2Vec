{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from top2vec.Top2Vec import Top2Vec\n",
    "from top2vec.similarity import (\n",
    "    describe_closest_items,\n",
    "    find_closest_items,\n",
    "    generate_similarity_matrix,\n",
    "    generate_csr_similarity_matrix,\n",
    ")\n",
    "import gensim\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "\n",
    "FIG_SIZE = (30, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 20 newsgroups data\n",
    "newsgroups_train = fetch_20newsgroups(\n",
    "    subset=\"all\", remove=(\"headers\", \"footers\", \"quotes\")\n",
    ")\n",
    "# newsgroups_documents = newsgroups_train.data[0:2000]\n",
    "newsgroups_documents = newsgroups_train.data\n",
    "\n",
    "# train top2vec model with doc_ids provided\n",
    "doc_ids = [str(num) for num in range(0, len(newsgroups_documents))]\n",
    "top2vec_model = Top2Vec(\n",
    "    documents=newsgroups_documents,\n",
    "    document_ids=doc_ids,\n",
    "    speed=\"fast-learn\",\n",
    "    workers=8,\n",
    "    umap_args={\"random_state\": 1337},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sklearn.metrics\n",
    "from top2vec.cutoff_heuristics import (\n",
    "    find_elbow_index,\n",
    "    get_distances_from_line,\n",
    "    find_cutoff,\n",
    "    _get_shifted_second_derivative,\n",
    "    ELBOW_HEURISTIC_STR,\n",
    "    DERIVATIVE_HEURISTIC_STR,\n",
    "    AVERAGE_HEURISTIC_STR,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Going to make a cumulative density function showing the move from A to B.\n",
    "# index[A] shows how much of the total variation has been accomplished BEFORE index A\n",
    "# Therefore an elbow of A should be thought of as exclusive, not inclusive\n",
    "def get_cdf_of_differences(sorted_values):\n",
    "    # print(f\"Generating CDF for {len(sorted_values)} values\")\n",
    "    # print(\"% of total difference: \", percent_of_total_difference)\n",
    "    # Deal with floating point errors\n",
    "    return np.cumsum(get_percent_of_total_differences(sorted_values)).round(decimals=8)\n",
    "\n",
    "\n",
    "def get_percent_of_total_differences(sorted_values):\n",
    "    total_difference = sorted_values[-1] - sorted_values[0]\n",
    "    differences = np.hstack((0, sorted_values[1:] - sorted_values[:-1]))\n",
    "    # print(\"Total difference: \", total_difference)\n",
    "    # print(\"Difference for values up to i: \", differences[:20])\n",
    "    percent_of_total_difference = differences / total_difference\n",
    "    return percent_of_total_difference\n",
    "\n",
    "\n",
    "def plot_heuristic(\n",
    "    values,\n",
    "    figure_num=\"1\",\n",
    "    figsize=FIG_SIZE,\n",
    "    first_elbow=True,\n",
    "    below_line_exclusive=True,\n",
    "):\n",
    "    sorted_values = -np.sort(-np.array(values))\n",
    "    x = np.arange(sorted_values.size)\n",
    "\n",
    "    m = (sorted_values[-1] - sorted_values[0]) / (sorted_values.size - 1)\n",
    "    line = x * m + sorted_values[0]\n",
    "\n",
    "    # Uniform is an absolute value and therefore useless for detecting an inflection\n",
    "    # y_distances = get_distances_from_line(\n",
    "    #    sorted_values, m, sorted_values[0], metric=\"raw-y\", first_elbow=False\n",
    "    # ).distances\n",
    "\n",
    "    elbow = find_cutoff(\n",
    "        sorted_values,\n",
    "        cutoff_heuristic=ELBOW_HEURISTIC_STR,\n",
    "        first_elbow=first_elbow,\n",
    "        below_line_exclusive=below_line_exclusive,\n",
    "    )\n",
    "    distances_tuple = get_distances_from_line(\n",
    "        sorted_values, m, sorted_values[0], first_elbow=first_elbow\n",
    "    )\n",
    "    y_distances = distances_tuple.y_deltas\n",
    "\n",
    "    slid_second_derivative = _get_shifted_second_derivative(\n",
    "        sorted_values, distances_tuple.is_truncated, distances_tuple.truncation_index\n",
    "    )\n",
    "    scores = (\n",
    "        distances_tuple.distances[: distances_tuple.truncation_index + 1]\n",
    "        * slid_second_derivative\n",
    "    )\n",
    "    alt_elbow = find_cutoff(\n",
    "        sorted_values,\n",
    "        cutoff_heuristic=DERIVATIVE_HEURISTIC_STR,\n",
    "        first_elbow=first_elbow,\n",
    "        below_line_exclusive=below_line_exclusive,\n",
    "    )\n",
    "    average_elbow = find_cutoff(\n",
    "        sorted_values,\n",
    "        cutoff_heuristic=AVERAGE_HEURISTIC_STR,\n",
    "        first_elbow=first_elbow,\n",
    "        below_line_exclusive=below_line_exclusive,\n",
    "    )\n",
    "    ELBOW_COLOR = \"blue\"\n",
    "    DERIVATIVE_COLOR = \"orange\"\n",
    "    AVERGE_COLOR = \"green\"\n",
    "    # PLOTS ON PLOTS\n",
    "    fig = plt.figure(num=figure_num, clear=True, figsize=figsize)\n",
    "\n",
    "    gs = fig.add_gridspec(nrows=3, ncols=3)\n",
    "    ax = fig.add_subplot(gs[:2, 0])\n",
    "    ax.plot(line)\n",
    "    ax.scatter([elbow], [sorted_values[elbow]], color=ELBOW_COLOR)\n",
    "    ax.scatter([alt_elbow], [sorted_values[alt_elbow]], color=DERIVATIVE_COLOR)\n",
    "    ax.scatter([average_elbow], [sorted_values[average_elbow]], color=AVERGE_COLOR)\n",
    "    ax.plot(sorted_values)\n",
    "\n",
    "    ax_y = fig.add_subplot(gs[2, 0])\n",
    "    ax_y.axhline(0, color=\"black\")\n",
    "    ax_y.plot(y_distances)\n",
    "    ax_y.scatter([elbow], [y_distances[elbow]], color=ELBOW_COLOR)\n",
    "    ax_y.scatter([alt_elbow], [y_distances[alt_elbow]], color=DERIVATIVE_COLOR)\n",
    "    ax_y.scatter([average_elbow], [y_distances[average_elbow]], color=AVERGE_COLOR)\n",
    "\n",
    "    ax_d = fig.add_subplot(gs[0, 1])\n",
    "    ax_d.plot(distances_tuple.distances[: distances_tuple.truncation_index + 1])\n",
    "    ax_d.axhline(0, color=\"black\")\n",
    "    ax_d.scatter([elbow], [distances_tuple.distances[elbow]], color=ELBOW_COLOR)\n",
    "    ax_d.xaxis.set_ticklabels([])\n",
    "    ax_val_second_d = fig.add_subplot(gs[1, 1])\n",
    "    ax_val_second_d.plot(slid_second_derivative)\n",
    "    ax_val_second_d.scatter(\n",
    "        [alt_elbow], [slid_second_derivative[alt_elbow]], color=DERIVATIVE_COLOR\n",
    "    )\n",
    "    ax_val_second_d.axhline(0, color=\"black\")\n",
    "    ax_val_scores = fig.add_subplot(gs[2, 1])\n",
    "    ax_val_scores.plot(scores)\n",
    "    ax_val_scores.scatter([alt_elbow], [scores[alt_elbow]], color=DERIVATIVE_COLOR)\n",
    "    ax_val_scores.axhline(0, color=\"black\")\n",
    "    return elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does one of our topics look like?\n",
    "\n",
    "topn = 100000\n",
    "topic_descriptions = describe_closest_items(\n",
    "    top2vec_model.topic_vectors,\n",
    "    top2vec_model.word_vectors,\n",
    "    top2vec_model.vocab,\n",
    "    topn=topn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if top2vec_model.get_num_topics() > 20:\n",
    "    top2vec_model.hierarchical_topic_reduction(20)\n",
    "    print(f\"Reduced to {len(top2vec_model.topic_vectors_reduced)} topics.\")\n",
    "    topn = 100000\n",
    "    topic_descriptions_reduced = describe_closest_items(\n",
    "        top2vec_model.topic_vectors_reduced,\n",
    "        top2vec_model.word_vectors,\n",
    "        top2vec_model.vocab,\n",
    "        topn=topn,\n",
    "    )\n",
    "else:\n",
    "    print(f\"Already at {top2vec_model.get_num_topics()} topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_num = min(20, top2vec_model.get_num_topics() - 1)\n",
    "print(f\"TOPIC {topic_num}\")\n",
    "display_limit = -1\n",
    "terms, scores = topic_descriptions[topic_num]\n",
    "print(len(scores), \" total similar terms found from raw data.\")\n",
    "raw_scores = (\n",
    "    1\n",
    "    - sklearn.metrics.pairwise_distances(\n",
    "        np.array([top2vec_model.topic_vectors[topic_num]]), top2vec_model.word_vectors\n",
    "    )\n",
    ")[0]\n",
    "plot_heuristic(\n",
    "    raw_scores,\n",
    "    f\"Topic {topic_num} - Raw Cosine\",\n",
    ")\n",
    "\n",
    "# Now show what the elbow would be if you ran it twice\n",
    "# Need to spcify first_elbow=False, otherwise you can run into some bad cases\n",
    "elbow_twice = plot_heuristic(\n",
    "    scores,\n",
    "    f\"Topic {topic_num} - Values\",\n",
    "    first_elbow=False,\n",
    ")\n",
    "print(f\"Running heuristic twice gives {elbow_twice} terms: \", terms[:elbow_twice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_matrix = generate_similarity_matrix(\n",
    "    top2vec_model.document_vectors, top2vec_model.topic_vectors, topn=topn\n",
    ")\n",
    "doc_topic_num_zeroes = np.count_nonzero(doc_topic_matrix == 0)\n",
    "doc_topic_sparsity = doc_topic_num_zeroes / (doc_topic_matrix.size)\n",
    "\n",
    "topic_term_matrix = generate_similarity_matrix(\n",
    "    top2vec_model.topic_vectors, top2vec_model.word_vectors, topn=topn\n",
    ")\n",
    "topic_term_num_zeroes = np.count_nonzero(topic_term_matrix == 0)\n",
    "topic_term_sparsity = topic_term_num_zeroes / (topic_term_matrix.size)\n",
    "\n",
    "doc_topic_sparsity, topic_term_sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b406a096e8e92be6ba761b64451312115eefe9ae1d936dc5da356c788b101664"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
