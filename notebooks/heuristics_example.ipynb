{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from top2vec.Top2Vec import Top2Vec\n",
    "from top2vec.similarity import (\n",
    "    describe_closest_items,\n",
    "    find_closest_items,\n",
    "    generate_similarity_matrix,\n",
    "    generate_csr_similarity_matrix,\n",
    ")\n",
    "import gensim\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "\n",
    "FIG_SIZE = (30, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 20 newsgroups data\n",
    "newsgroups_train = fetch_20newsgroups(\n",
    "    subset=\"all\", remove=(\"headers\", \"footers\", \"quotes\")\n",
    ")\n",
    "# newsgroups_documents = newsgroups_train.data[0:2000]\n",
    "newsgroups_documents = newsgroups_train.data\n",
    "\n",
    "# train top2vec model with doc_ids provided\n",
    "doc_ids = [str(num) for num in range(0, len(newsgroups_documents))]\n",
    "top2vec_model = Top2Vec(\n",
    "    documents=newsgroups_documents,\n",
    "    document_ids=doc_ids,\n",
    "    speed=\"fast-learn\",\n",
    "    workers=8,\n",
    "    umap_args={\"random_state\": 1337},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sklearn.metrics\n",
    "from top2vec.elbow_finding import find_elbow_index, get_distances_from_line\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Going to make a cumulative density function showing the move from A to B.\n",
    "# index[A] shows how much of the total variation has been accomplished BEFORE index A\n",
    "# Therefore an elbow of A should be thought of as exclusive, not inclusive\n",
    "def get_cdf_of_differences(sorted_values):\n",
    "    # print(f\"Generating CDF for {len(sorted_values)} values\")\n",
    "    # print(\"% of total difference: \", percent_of_total_difference)\n",
    "    # Deal with floating point errors\n",
    "    return np.cumsum(get_percent_of_total_differences(sorted_values)).round(decimals=8)\n",
    "\n",
    "def get_percent_of_total_differences(sorted_values):\n",
    "    total_difference = sorted_values[-1] - sorted_values[0]\n",
    "    differences = np.hstack((0,\n",
    "        sorted_values[1:] - sorted_values[:-1]))\n",
    "    # print(\"Total difference: \", total_difference)\n",
    "    #print(\"Difference for values up to i: \", differences[:20])\n",
    "    percent_of_total_difference = differences / total_difference\n",
    "    return percent_of_total_difference\n",
    "\n",
    "def plot_heuristic(\n",
    "    values,\n",
    "    figure_num=\"1\",\n",
    "    derivatives=\"distance\",\n",
    "    figsize=FIG_SIZE,\n",
    "    first_elbow=True,\n",
    "    elbow_metric=\"manhattan\",\n",
    "    display_limit=100,\n",
    "):\n",
    "    sorted_vals = -np.sort(-np.array(values))\n",
    "    x = np.arange(sorted_vals.size)\n",
    "\n",
    "    m = (sorted_vals[-1] - sorted_vals[0]) / (sorted_vals.size - 1)\n",
    "    line = x * m + sorted_vals[0]\n",
    "    # Uniform is an absolute value and therefore useless for detecting an inflection\n",
    "    y_distances = get_distances_from_line(\n",
    "        sorted_vals, m, sorted_vals[0], metric=\"raw-y\", first_elbow=False\n",
    "    )\n",
    "    elbow = find_elbow_index(sorted_vals, first_elbow=first_elbow, metric=elbow_metric)\n",
    "    np.argmax(get_cdf_of_differences(sorted_vals))\n",
    "    print(f\"Raw elbow: {elbow}\")\n",
    "\n",
    "    if not derivatives:\n",
    "        distances = []\n",
    "        with_derivatives = False\n",
    "    elif derivatives == \"distance\":\n",
    "        distances = get_distances_from_line(\n",
    "            sorted_vals, m, sorted_vals[0], first_elbow=False, metric=elbow_metric\n",
    "        )\n",
    "        with_derivatives = True\n",
    "    elif derivatives == \"values\":\n",
    "        distances = sorted_vals\n",
    "        with_derivatives = True\n",
    "    else:\n",
    "        raise ValueError(\"Unknown derivatives requested.\")\n",
    "\n",
    "    plot_figure(\n",
    "        sorted_vals,\n",
    "        distances,\n",
    "        elbow,\n",
    "        line,\n",
    "        figure_num=figure_num,\n",
    "        with_derivatives=with_derivatives,\n",
    "        y_distances=y_distances,\n",
    "        figsize=figsize,\n",
    "        display_limit=display_limit,\n",
    "    )\n",
    "    return elbow\n",
    "\n",
    "\n",
    "def plot_figure(\n",
    "    sorted_vals,\n",
    "    distances,\n",
    "    elbow,\n",
    "    line,\n",
    "    figure_num=\"1\",\n",
    "    with_derivatives=True,\n",
    "    y_distances=None,\n",
    "    figsize=FIG_SIZE,\n",
    "    display_limit = -1,\n",
    "):\n",
    "\n",
    "    distances_prime = [\n",
    "        0,\n",
    "    ]\n",
    "    for x, distance in enumerate(distances):\n",
    "        if x == 0:\n",
    "            continue\n",
    "        else:\n",
    "            distances_prime.append(distance - distances[x - 1])\n",
    "    distances_prime_prime = [0, 0]\n",
    "    for x, distance_prime in enumerate(distances_prime):\n",
    "        if x == 0:\n",
    "            continue\n",
    "        else:\n",
    "            distances_prime_prime.append(distance_prime - distances_prime[x - 1])\n",
    "\n",
    "    if not with_derivatives:\n",
    "        fig = plt.figure(num=figure_num, clear=True, figsize=figsize)\n",
    "        gs = fig.add_gridspec(nrows=3, ncols=1)\n",
    "        if y_distances is not None:\n",
    "            ax = fig.add_subplot(gs[:2, 0])\n",
    "            ax_y = fig.add_subplot(gs[2, 0], sharex=ax)\n",
    "            ax_y.axhline(0, color=\"black\")\n",
    "            ax_y.plot(y_distances[:display_limit])\n",
    "            if display_limit < 0 or elbow < display_limit:\n",
    "                ax_y.scatter([elbow], [y_distances[elbow]])\n",
    "        else:\n",
    "            ax = fig.add_subplot(gs[:, 0])\n",
    "\n",
    "    else:\n",
    "        fig = plt.figure(num=figure_num, clear=True, figsize=figsize)\n",
    "        gs = fig.add_gridspec(nrows=3, ncols=3)\n",
    "        if y_distances is not None:\n",
    "            ax = fig.add_subplot(gs[:2, 0])\n",
    "            ax_y = fig.add_subplot(gs[2, 0])\n",
    "            ax_y.axhline(0, color=\"black\")\n",
    "            ax_y.plot(y_distances[:display_limit])\n",
    "            if display_limit < 0 or elbow < display_limit:\n",
    "                ax_y.scatter([elbow], [y_distances[elbow]])\n",
    "        else:\n",
    "            ax = fig.add_subplot(gs[:, 0])\n",
    "        ax_d = fig.add_subplot(gs[0, 1])\n",
    "        ax_d.plot(distances[:display_limit])\n",
    "        ax_d.axhline(0, color=\"black\")\n",
    "        ax_d.xaxis.set_ticklabels([])\n",
    "        ax_d_prime = fig.add_subplot(gs[1, 1], sharex=ax_d)\n",
    "        ax_d_prime.plot(distances_prime[:display_limit])\n",
    "        ax_d_prime.axhline(0, color=\"black\")\n",
    "        ax_d_prime_prime = fig.add_subplot(gs[2, 1])\n",
    "        ax_d_prime_prime.plot(distances_prime_prime[:display_limit])\n",
    "        ax_d_prime_prime.axhline(0, color=\"black\")\n",
    "        \n",
    "        # Now it is the time for our differences and percent differences\n",
    "        percent_of_total = get_percent_of_total_differences(sorted_vals)\n",
    "        cdf = np.cumsum(percent_of_total).round(decimals=8)\n",
    "        other_elbow = np.argmax(percent_of_total)\n",
    "        ax_percent_of_tot = fig.add_subplot(gs[0, 2])\n",
    "        ax_percent_of_tot.plot(percent_of_total[:display_limit])\n",
    "        ax_percent_of_tot.scatter([other_elbow], [percent_of_total[other_elbow]])\n",
    "        ax_percent_of_tot.axhline(0, color=\"black\")\n",
    "        ax_cdf = fig.add_subplot(gs[1, 2], sharex=ax_percent_of_tot)\n",
    "        ax_cdf.plot(cdf)\n",
    "        ax_cdf.axhline(0, color=\"black\")\n",
    "        ax_cdf.axhline(1, color=\"black\")\n",
    "        print(f\"Biggest % total difference: {np.argmax(percent_of_total)}\")\n",
    "        # What about an elbow of the CDF?\n",
    "        ax_cdf_with_line = fig.add_subplot(gs[2,2], sharex=ax_percent_of_tot)\n",
    "        cdf_line_slope = 1 / (cdf.size - 1)\n",
    "        cdf_line = np.arange(cdf.size) * cdf_line_slope\n",
    "        ax_cdf_with_line.plot(cdf)\n",
    "        ax_cdf_with_line.plot(cdf_line)\n",
    "        cdf_dist_from_line = get_distances_from_line(cdf, cdf_line_slope, 0)\n",
    "        cdf_elbow = np.argmax(cdf_dist_from_line)\n",
    "        ax_cdf_with_line.scatter([cdf_elbow], [cdf[cdf_elbow]])\n",
    "        if cdf_elbow != elbow:\n",
    "            print(f\"CDF Elbow Disagrees: {cdf_elbow}\")\n",
    "\n",
    "\n",
    "    # Now the stuff for everyone\n",
    "    ax.plot(line[:display_limit])\n",
    "    if display_limit < 0 or elbow < display_limit:\n",
    "        ax.scatter([elbow], [sorted_vals[elbow]])\n",
    "    ax.plot(sorted_vals[:display_limit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does one of our topics look like?\n",
    "\n",
    "topn = 100000\n",
    "topic_descriptions = describe_closest_items(\n",
    "    top2vec_model.topic_vectors,\n",
    "    top2vec_model.word_vectors,\n",
    "    top2vec_model.vocab,\n",
    "    topn=topn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if top2vec_model.get_num_topics() > 20:\n",
    "    top2vec_model.hierarchical_topic_reduction(20)\n",
    "    print(f\"Reduced to {len(top2vec_model.topic_vectors_reduced)} topics.\")\n",
    "    topn = 100000\n",
    "    topic_descriptions_reduced = describe_closest_items(\n",
    "        top2vec_model.topic_vectors_reduced,\n",
    "        top2vec_model.word_vectors,\n",
    "        top2vec_model.vocab,\n",
    "        topn=topn,\n",
    "    )\n",
    "else:\n",
    "    print(f\"Already at {top2vec_model.get_num_topics()} topics\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_num = min(20, top2vec_model.get_num_topics() -1)\n",
    "print(f\"TOPIC {topic_num}\")\n",
    "display_limit = -1\n",
    "terms, scores = topic_descriptions[topic_num]\n",
    "print(len(scores), \" total similar terms found from raw data.\")\n",
    "raw_scores = (\n",
    "    1\n",
    "    - sklearn.metrics.pairwise_distances(\n",
    "        np.array([top2vec_model.topic_vectors[topic_num]]), top2vec_model.word_vectors\n",
    "    )\n",
    ")[0]\n",
    "plot_heuristic(\n",
    "    raw_scores,\n",
    "    f\"Topic {topic_num} - Raw Cosine\",\n",
    "    derivatives=\"values\",\n",
    "    display_limit=display_limit,\n",
    ")\n",
    "\n",
    "# Now show what the elbow would be if you ran it twice\n",
    "# Need to spcify first_elbow=False, otherwise you can run into some bad cases\n",
    "elbow_twice = plot_heuristic(\n",
    "    scores,\n",
    "    f\"Topic {topic_num} - Values\",\n",
    "    derivatives=\"values\",\n",
    "    display_limit=display_limit,\n",
    "    first_elbow=False,\n",
    ")\n",
    "print(f\"Running heuristic twice gives {elbow_twice} terms: \", terms[:elbow_twice])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_matrix = generate_similarity_matrix(\n",
    "    top2vec_model.document_vectors, top2vec_model.topic_vectors, topn=topn\n",
    ")\n",
    "doc_topic_num_zeroes = np.count_nonzero(doc_topic_matrix == 0)\n",
    "doc_topic_sparsity = doc_topic_num_zeroes / (doc_topic_matrix.size)\n",
    "\n",
    "topic_term_matrix = generate_similarity_matrix(\n",
    "    top2vec_model.topic_vectors, top2vec_model.word_vectors, topn=topn\n",
    ")\n",
    "topic_term_num_zeroes = np.count_nonzero(topic_term_matrix == 0)\n",
    "topic_term_sparsity = topic_term_num_zeroes / (topic_term_matrix.size)\n",
    "\n",
    "doc_topic_sparsity, topic_term_sparsity"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b406a096e8e92be6ba761b64451312115eefe9ae1d936dc5da356c788b101664"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
